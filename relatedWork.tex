%!TEX root = ./main.tex

\section{Related Work}
\label{sec:related}

\btext{Bologna? Related work di deviant accorciati + i danesi + deviant?}

%Process discovery is generally considered a challenging task of process mining~\cite{2012-Maggi}. The majority of works in this field are focused on discovering a business process model from a set of input traces that are supposed compliant with it. In this sense, process discovery can be seen as the application of a machine learning technique to extract a grammar from a set of positive sample data. Angluin et al. \cite{1983-Angliun} provide an interesting overview on this wide field.
%Differently from grammar learning, where the model is often expressed with automata, regular expressions or production rules, process discovery usually adopts formalisms that can express concurrency and synchronization in a more understandable way \cite{2009-Goedertier}. 
%The language to express the model is a crucial point, which inevitably influences the learning task itself. Indeed, the two macro-categories of business process discovery approaches---procedural and declarative---differ precisely by the type of language to express the model.%: procedural approaches envisage to uncover structured processes, whereas declarative ones are more suitable for unstructured models. 
%Well known examples of procedural process discoverer are the ones presented in the works \cite{2003-Weijters,2004-Aalst,2007-Gunther,2010-Aalst,2013-Leemans,2015-Guo,2017-Augusto,2019-Augusto}. %In particular, the $\alpha$-algorithm \cite{2004-Aalst} is one of the first and most famous process discovery approaches. Its simple structure does not allow the discovery of complicated routing constructs and can be negatively influenced by the presence of noise in the log. Definitely more robust techniques are the heuristics miner \cite{2003-Weijters} and the fuzzy miner \cite{2007-Gunther}, which can deal with unbalanced, incomplete, or noisy logs. %The work \cite{2010-Aalst} seeks a overfitting/underfitting balance between different parts of the extracted model by means of a two-step approach. The first step builds a transition system from the observation of occurrence, sequence and multi-set of activities in the log's traces. The second step converts the transition system into a Petri net, which can easily express the procedural nature of the business process.
%In \cite{2019-Augusto}, Augusto et al. present an extensive review of the procedural approaches to process discovery with a BPMN or Petri net output. Similarly to our approach, the comparison between the various tools is conducted on the basis of fitness, precision, generalisation and complexity. %The result of this comparison highlights how Inductive Miner \cite{2015-Guo}, Evolutionary Tree Miner \cite{2013-Leemans}, and Split Miner \cite{2017-Augusto} outperform all the other approaches, despite being rather limited when dealing with large-scale unfiltered logs.
%Like most procedural approaches to process discovery, all these works contemplate the presence of non-informative noise in the log, which should be separated from the rest of the log and disregarded.
%Like most procedural approaches to process discovery, all the works described so far consider deviant examples as a form of non-informative noise in the log, which should be separated from the rest of the log and disregarded.
 
Traditional declarative approaches to process discovery stem from the necessity of a more friendly language than the procedural one to express loosely-structured processes. Indeed, process models are sometimes less structured than one could expect~\cite{2012-Maggi}. The application of a procedural discovery could produce spaghetti-models. In that case, a declarative approach is more suitable to briefly list all the required or prohibited behaviours in a business process.

Several declarative process discovery approaches have been proposed in the literature~\cite{2011-Maggi,2012-Maggi,2015-DiCiccio,2012-Schunselaar}.
%Similarly to our technique, the one exposed by Maggi et al. 
The approach in~\cite{2011-Maggi} starts by considering the set of all activities in the log and building a set of all possible candidate Declare constraints. %That work stems from the idea that Apriori-like approaches---such as sequence mining~\cite{1994-Agrawal} and episode mining \cite{1997-Mannila}---can discover local patterns in a log, but not rules representing prohibited behaviours and choices. Therefore, differently from our algorithm, the candidate Declare constraints are then translated into the equivalent \ac{LTL} and checked (one at a time) against all the log content employing the technique of \cite{2005-Aalst}.
 The process continue until certain levels of recall and specificity are reached. The performance of this technique is improved in \cite{2012-Maggi} with an interesting two-step approach to both reduce the search space of candidate constraints and exclude from the model those \ac{LTL} formulas that are vacuously satisfied.
Also the work \cite{2012-Schunselaar} by Schunselaar et al. proposes a model refinement to efficiently exclude vacuously satisfied constraints. %Interestingly, instead of learning the model from the structure of a single trace, this approach works on sets of traces in the event log.
The MINERFul approach described in \cite{2015-DiCiccio} proposes to employ four metrics to guide the declarative discovery approach: support, confidence and interest factor for each constraint w.r.t. the log, and the possibility to include in the search space constraints on prohibited behaviours.
The work by Di Ciccio et al. \cite{2017-DiCiccio} focuses on refining Declare models to remove the frequent redundancies and inconsistencies. 
%The algorithms and the hierarchy of constraints described in that work were particularly inspiring to define our discovery procedure.
Similarly to the procedural approaches, all the declarative ones described so far do not deal with negative examples, although the vast majority of them envisage the possibility to discard a portion of the log by setting thresholds on the value of specific metrics that the discovered model should satisfy.
 
%In the wider field of grammar learning, the foundational work by Gold \cite{1967-Gold} showed how negative examples are crucial to distinguish the right hypothesis among an infinite number of grammars that fit the positive examples. Both positive and negative examples are required to discover a grammar with perfect accuracy. Since process discovery does not usually seek perfection, but only a good performance according to defined metrics, it is not surprising that many procedural and declarative discoverers disregard the negative examples. Nonetheless, in this work we instead claim that negative traces are extremely important when learning declarative process models.%\tododl{qui ho levato alcuni lavori tradizionali su grammar learning.}
%Among traditional grammar learning approaches, the ones by Angluin \cite{1987-Angluin} and Mooney \cite{1995-Mooney} are particularly relevant for our work.
%The article \cite{1987-Angluin} focuses on identifying an unknown model referred as ``regular set'' and represented through Deterministic Finite-state Acceptor (DFA). Coherently with Gold's theory  \cite{1967-Gold}, Angluin propose a learning algorithm that starts from input examples of the regular set's members and non-members. The learning process is realised through the construction of an ``observation table''. The approach of Mooney et al. \cite{1995-Mooney} shows three different algorithms to learn Conjunctive Normal Form (CNF), Disjunctive Normal Form (DNF) and Decision trees from a set of positive and negative examples. 
 
The information contained in the negative examples is actively used in a subset of the declarative process discovery approaches \cite{2007-Lamma,2009-Chesani,2010-Bellodi,2016-Bellodi}. All these works can be connected to the basic principles of the \ac{ICL} algorithm \cite{1995-DaRaedt}, whose functioning principle is intrinsically related to the availability of both negative and positive examples. 
The \ac{DPML} described in \cite{2007-Lamma,2007b-Lamma} by Lamma et al. focuses on learning integrity constraints expressed as logical formulas. The constraints are later translated into an equivalent construct of the declarative graphical language DecSerFlow \cite{2006-Aalst}. Similarly to this approach, the DecMiner tool described in \cite{2009-Chesani}, learns a set of SCIFF rules \cite{2008-Alberti} which correctly classify an input set of labelled examples. Such rules are then translated into ConDec constraints \cite{2006-Pesic}. Differently from \cite{2009-Chesani}, the present work directly learns Declare constraints without any intermediate language.
%\tcolor{blue}{An important difference w.r.t our approach is precisely in the fact that \cite{2009-Chesani} expressly requires negative examples to perform the classification, whereas the algorithm we propose can work even in absence of counterexamples.\tododl{NO, 10 passa da rappresentazione SCIFF mentre noi lavoriamo direttamente sui template declare}}
\ac{DPML} has been later used in \cite{2010-Bellodi} to extract integrity constraints, then converted into Markov Logic formulas. The weight of each formula is determined with a statistical relational learning tool. %Indeed, some process discovery approaches take inspiration from the methods to learn the probability distributions of stochastic generative grammars over sets of observed examples (1997,Ghahramani) (Kersting et al., 2006) (1997,Smyth) (2003,Cadez )
Taking advantage of the negative examples, the approach of \cite{2010-Bellodi}  is improved in \cite{2016-Bellodi}, thus obtaining significantly better results than other process discovery techniques. 
Since for all these works the availability of negative examples is crucial, recent years have seen the development of synthetical log generators able to produce not only positive but also negative process cases \cite{2019-Chesani,2017-Chesani,2020-Loreti,2009-Goedertier,2014-Stocker,2010-Hee}. In the experimental evaluation of this work, we employ the abductive-logic generator by Loreti et al. \cite{2020-Loreti} to synthesise part of the input event logs.
 
Particularly related to our approach are the works by Neider et al. \cite{2018-Neider}, Camacho et al. \cite{2019-Camacho}, and Reiner \cite{2019-Riener} where a SAT-based solver is employed to learn a simple set of LTL formulas consistent with an input data set of positive and negative examples. In particular, Neider et al. \cite{2018-Neider} employ decision tree to improve the performance and manage large example sets; Camacho et al. \cite{2019-Camacho} exploit the correspondence of LTL formulae with Alternating Finite Automata (AFA); whereas Reiner uses partial Directed Acyclic Graphs (DAGs) to decompose the search space into smaller subproblems.
The concept of negative example used in this work could be related to both the definitions of syntactical and semantic noise of \cite{2009-Gunther}. In particular, besides being able to extract relevant syntactic information that characterise the positive examples w.r.t. negative, our approach could also be useful to deal with the semantic concept of modification noise i.e., the semantic difference between traces from the same process model, which has been partially or totally modified at a certain point in time.  As a minor point, we also might notice that these works provides in output LTL formulas, while we opt for Declare formulas with LTL$_f$ semantics.
 
%It is important to underline that also a limited number of procedural approaches envisage the need for taking into account the information contained into the negative examples. 
%In particular, the work \cite{2015-Ponce} showed how negative examples can be employed to alleviate problems like log incompleteness and noise.
%The AGNEs tool described in \cite{2009-Goedertier} increases the dimension of an event log with artificially generated negative examples, then uses \ac{ILP} multi-relational classification to discover a Petri net model. 
%Negative examples are generated in a rather syntactical way, by adding a unique negative event at the end of a positive trace. This concept is extended in the work of Ponce de Leon et al. \cite{2018-Ponce} which envisage the concatenations of a sequence of negative events. Differently from these approaches, our technique does not assume syntactical restrictions on the input negative examples.

%\ac{ILP} is also used in \cite{2006-Ferreira}, where the authors suppose a set of negative examples provided by domain experts. The approach uses partial-order planning to discover a structured model. More recently, the works \cite{2014-Broucke,2014-BrouckePhD} showed how synthetically generated traces can be employed to improve the robustness of the compliance monitor task. 
 
Deviant cases---intended as traces whose sequence of activities deviates from the expected behaviour---are the subject of deviance mining approaches reviewed and evaluated by Nguyen et al. in \cite{2016-Nguyen}. Some applications of deviance mining tend to highlight the differences between models discovered from deviant and non-deviant traces \cite{2014-Suriadi,2014-Armas}. Other works intend deviance mining as a classification task, where the miner is required to identify normal and deviant traces given a set of examples. The classification inherently causes the discovery of patterns which distinguish different types of traces. In this sense, deviance mining is particularly similar to sequence classification. The discovered patterns can be based on the simple frequency of individual activities as in \cite{2013-Suriadi,2015-Partington}, their co-occurrence as in \cite{2011-Swinnen}, or the occurrence of specific subsequences \cite{2013-Bose,2007-Lo,2016-Bernardi}.
 
 
%Add someware something on Discovery with DCR graphs (https://dblp.uni-trier.de/pers/hd/s/Slaats:Tijs) https://link.springer.com/chapter/10.1007%2F978-3-030-21290-2_37
%
%https://link.springer.com/chapter/10.1007%2F978-3-642-32885-5_6
%http://ceur-ws.org/Vol-1021/paper_10.pdf
%
%negation of declare constraints:
%https://www.researchgate.net/publication/284570318_Patterns_for_a_Log-Based_Strengthening_of_Declarative_Compliance_Models
%
%process mining ibrido
%https://link.springer.com/article/10.1007/s13740-020-00112-9
